{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from C:/Users/LEGION/.lmstudio/models/RichardErkhov/mistralai_-_Mistral-7B-Instruct-v0.2-gguf/Mistral-7B-Instruct-v0.2.Q4_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = .\n",
      "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 32000\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  217 tensors\n",
      "llama_model_loader: - type q5_K:    8 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Small\n",
      "print_info: file size   = 3.86 GiB (4.57 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = .\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  3947.87 MiB\n",
      "..................................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 4096\n",
      "llama_init_from_model: n_ctx_per_seq = 4096\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 1000000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_init_from_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   296.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': '.', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.vocab_size': '32000', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '14', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(\n",
    "    model_path=\"C:/Users/LEGION/.lmstudio/models/RichardErkhov/mistralai_-_Mistral-7B-Instruct-v0.2-gguf/Mistral-7B-Instruct-v0.2.Q4_K_S.gguf\",\n",
    "    n_ctx=4096 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(text , query):\n",
    "    prompt = f\"\"\"\n",
    "        You are an AI assistant tasked with extracting accurate key insights from the provided text.  \n",
    "        Strictly refer only to the given content and do not generate any information that is not explicitly stated in it.  \n",
    "\n",
    "        ### Instructions:\n",
    "        1. Base your responses solely on the provided text.\n",
    "        2. If the information is not present, state: \"The document does not contain this information.\"\n",
    "        3. Do not make assumptions or infer details beyond the given content.\n",
    "        4. Extract key insights concisely and accurately.  \n",
    "\n",
    "        ### Provided Text:\n",
    "        {text}\n",
    "\n",
    "        ### Queries to Answer:\n",
    "        [{query}]\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text,query):\n",
    "    response = llm(\n",
    "        get_prompt(text,query),\n",
    "        max_tokens=2048,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_tokens(response, max_tokens=1200):\n",
    "    num_tokens = len(response.split())  \n",
    "    if num_tokens > max_tokens:\n",
    "        truncated_prompt = ' '.join(response.split()[:max_tokens])\n",
    "        return truncated_prompt\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting Details Using Resume</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jay Jajoo \\n+1-857-351-1933 | jayjajoo02@gmail.com  | https://www.linkedin.com/in/jay -jajoo-64958b15a | https://github.com/JayJajoo \\n \\nEducation \\nNortheastern University (Khoury  College) - Boston, MA                                 CGPA – 4.0/4.0 \\nMasters of Science in Data Science                           Sept 2024 – Dec 2026 \\nCourse Work :- NLP, Algorithms, Supervised Machine Learning, Data Management and Preprocessing \\nVellore Institute of Technology – Tamil Nadu, India                                               CGPA – 9.05/10 \\nB.Tech. in Computer Science and Engineering           Sept 2020 –May 2024 \\nCourse Work :- Machine Learning , Statistics, DBMS, OS, COA, DSA, Parallel Programming and Paradigms \\n \\nTechnical Skills \\nLanguages: Python, Javascript, C++, Java, HTML, CSS, MySQL, C \\nFrameworks : Flask, React, Node.js, Express.js , MongoDB \\nLibraries: TensorFlow, Py-Torch, NumPy, Pandas, Scikit-learn, Keras, NLTK, PySpark \\nDeveloper Tools: Git, AWS, Google Collab, Kaggle, VS Code, Visual Studio, PyCharm, IntelliJ, Eclipse,  \\nExperience \\nData Science Intern – Imagine Web Technologies                                          Jan 2024 – Jul 2024 \\n• Curated, refined, and processed diverse customer data, conducted comprehensive exploratory data analysis (EDA) to extract \\npivotal insights, and engineered advanced features to drive predictive excellence. \\n• Architected and deployed a Feedforward Neural Network in PyTorch, achieving an F1 score of 0 .89 for customer conversion \\nprediction, while optimizing model architecture and hyperparameters to ensure sustained high performance. \\nProjects \\n \\nHome Anomaly Detection | Py-Torch, LSTM Autoencoder                                                                                                    Sept 2024 – Dec 2024 \\n• Consolidated and analyzed data from 30 text files, performing data cleaning, feature extraction, and preprocessing, followed \\nby evaluating three anomaly detection models: Isolation Forest, DBSCAN, and LSTM Autoencoders. \\n• Attained exceptional performance in anomaly detection through LSTM Autoencoders, ensuring minimal reconstruction errors \\nand defining a precise threshold at the 95th percentile, culminating in a threshold for reconstruction error of 0.016%.  \\nObject Detection and 3D coordinates prediction (ML) | Python, Mi-DAS, Yolo              Sept 2024 – Dec 2024 \\n• Integrated YOLOv8 for object detection and MiDaS for depth estimation, delivering effective real -time 3D perception for \\nautonomous driving, despite a depth prediction loss of approximately 130 meters per image.  \\n• Conducted training of YOLOv5 and YOLOv8 models with various configurations, where YOLOv8 Medium (no data augmentation) \\nachieved optimal performance with precision of 0.9418, recall of 0.8908, mAP50 of 0.9391, and mAP50:90 of 0.889.  \\nFungi Classification using Deep Learning (ML) | Tensorflow, VGG156, ResNet50, IncV3             Dec 2023 – May 2024 \\n• Engineered a highly accurate ResNet deep learning model for fungal classification, achieving 98.90% accuracy. Fine- tuned \\nhyper-parameters to optimize the model’s performance, reaching 92.29% accuracy and 90.46% precision.  \\n• Presented a research paper on this project, accepted for publication in Springer’s IDBA 2024. Received commendation for \\nthe innovative approach, with 85% of attendees expressing interest in future collaboration. \\nMetamorphic Malware Detection using RNN’s (ML) | Tensorflow, LSTM, Bi-LSTM, GRU               Jan 2023 –Mar 2023 \\n• Hyper-tuned RNN models , including LSTM, Bi-LSTM, GRU , to enhance metamorphic malware detection, achieving 93.25% \\naccuracy and surpassing other RNNs. Key processes encompassed data visualization, hybrid model development.  \\n• Submitted research on RNN performance at IEEE ICDSNS 2023, with findings published on 26 Sept 2023. The project showcased \\nsignificant advancements in malware detection, earning positive recognition within the academic community.  \\nSimplify Amazon (ML and Web Dev) | Express.js, React.js, Python                Jan 2023 – Mar 2023 \\n• Automated the extraction of product reviews from Amazon via advanced web scraping techniques using BeautifulSoup. Logistic \\nRegression was utilized to classify sentiments, resulting in 91% accuracy.  \\n• OpenAI API was employed for generating overall product summaries from user comments. Data visualization was achieved with \\nChart.js and D3.js, leading to a 25% reduction in analysis time.  \\nAchievements  \\n• Certified AWS Solutions Architect: Successfully completed AWS Solutions Architect certification with a score of 793 out of 1000, \\nachieving competencies in all parameters required by the certification.  \\n• Published Research Paper in IEEE - ICDSNS 2023 : Exhibited research paper titled Performance Comparison of RNNs for \\nMetamorphic Malwares at the distinguished IEEE conference ICDSNS 2023, published in the IEEE index on 26 Sept. 2023.  \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query =\"Extract key insights from the above text\"\n",
    "pdf_path = \"test.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(pdf_text,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting Details From My Research Paper</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"2023 International Conference on Data Science and Network Security (ICDSNS) \\n979-8-3503-0159-5/23/$31.00 ©2023 IEEE \\nPerformance Comparison of Recurrent Neural \\nNetworks for Metamorphic Malware \\n1st  Shubh Mittal \\nSchool of Computer Science and \\nEngineering \\nVellore Institute of Technology \\nVellore, India \\nshubh.mittal2020@vitstudent.ac.in \\n4th  Muskan Bansal \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\nmuskan.bansal2020@vitstudent.ac.in \\n2nd  Tisha Chawla \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\ntisha.chawla2020@vitstudent.ac.in \\n5th  Harsha Parashar \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\nharsha.parashar2020@vitstudent.ac.in \\n3rd  Jay Jajoo \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\njay.jajoo2020@vitstudent.ac.in \\n6th  Ruby D \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\nruby.d@vit.ac.in \\nAbstract—Metamorphic malware remains a significant \\nchallenge in the field of information security as i t constantly \\nchanges its code and structure, utilizing sophistic ated methods \\nto evade detection by antivirus software. This nece ssitates \\nadvanced techniques such as machine learning and de ep \\nlearning algorithms to effectively detect it. Howev er, the major \\nhurdles lie in the lack of a comprehensive dataset for training \\nalgorithms and the continuous evolution of metamorp hic \\nmalware. To bridge this research gap, a deep learni ng-based \\nmethod is proposed that employs bidirectional LSTM \\n(BiLSTM) to detect metamorphic malware based on attack \\nvectors. A comparative analysis is conducted of BiL STM's \\nperformance against other recurrent neural networks  (RNNs) \\nsuch as long short-term memory (LSTM), gated recurrent units \\n(GRU), and a hybrid model of BiLSTM and GRU. The mo dels \\nwere trained using a dataset comprising eight categ ories of \\nmetamorphic malware. The results demonstrate that B iLSTM \\nsurpasses other RNNs, achieving the highest accuracy of 93.25% \\ncompared to 93.20% for LSTM, 91.90% for GRU, and 86 .41% \\nfor the hybrid model. The use of the outer activati on function, \\nLinear, and the inner activation function, SoftSign , in \\nconjunction with the Adam optimizer, significantly contributed \\nto this achievement. The proposed approach has the potential to \\ngreatly enhance current malware detection technique s and \\nimprove the overall security of computer systems. Furthermore, \\nit can be extended to address other types of malwar e and cyber \\nthreats. By overcoming the challenges of limited tr aining \\ndatasets and the ever-evolving nature of metamorphic malware, \\nthis research offers practical advantages, includin g enhanced \\nthreat detection capabilities, reduced false positi ves, and \\nincreased system security.  \\nKeywords—Metamorphic Malware, API Calls, Bidirectio nal \\nLong Short Term Memory, Recurrent Neural Network, G ated \\nRecurrent Unit \\nI.  INTRODUCTION  \\nThe proliferation of malware attacks has led to an \\nincreased demand for advanced security measures. Ma lware \\nis a specific category of software that is created to damage \\ncomputers, compromise security, or steal sensitive data. The \\ntraditional approach to detecting malware is to use signature-\\nbased methods, where a database of known malware \\nsignatures is used to identify malware. However, th is \\napproach is ineffective against metamorphic malware, which \\nconstantly changes its code to avoid detection. \\nComputer systems are severely threatened by \\nmetamorphic malware, as it can go undetected for ex tended \\nperiods, allowing it to inflict severe damage. Deep  learning \\napplications have demonstrated promise in detecting  \\nmetamorphic malware. Machine learning is the supers et of \\ndeep learning, in which training of ANNs is done to discover \\npatterns from data. Deep learning has proven effect ive in \\ndifferent domains, including but not limited to identifying and \\nclassifying images, recognizing speech patterns, an d \\nprocessing natural language. In recent years, the \\nimplementation of its techniques has gained attenti on in the \\nmalware detection domain. The paper aims to develop a deep \\nlearning-based model that can effectively detect metamorphic \\nmalware. The project involves collecting a dataset of known \\nmetamorphic malware and benign software. The datase t is \\ntrained, and then the model is validated. The model  is built \\nusing state-of-the-art techniques such as CNNs (convolutional \\nneural networks) and RNNs. The project also involve s \\nevaluating the efficiency of the deep learning model on a test \\nset of previously unseen metamorphic malware and be nign \\nsoftware. The potential impact of this project is significant, as \\nmetamorphic malware is a growing threat that tradit ional \\nantivirus software is struggling to detect. By deve loping a \\nmodel that is capable of accurately detecting metam orphic \\nmalware, this project could help improve the securi ty of \\ncomputer systems and protect against cyberattacks. \\nII.  RELATED WORK  \\nDetecting metamorphic malware is a major challenge \\nbecause it is designed to constantly modify its cod e and \\nbehavioural, making it difficult for traditional de tection \\nmethods that rely on signatures to identify it. A r ecent paper \\n[1] utilizes genetic algorithms like J48 and deep n eural \\nnetworks, a novel approach was implemented to detec t \\nmalware and the strategy selectively generated generations of \\nmalware samples with an optimization technique to a chieve \\n5% better accuracy than other methods. Another stud y [2] \\nhighlights the effectiveness of anti-viruses agains t existing \\nmalware by using bypass detection, making the detec tion of \\nmalware difficult for the anti-virus software by in serting \\ngarbage values and substituting the instruction. The technique \\napplied in the study is the Hidden Markov Model (HMM).  A \\nscalable deep learning (DL) model is presented in [3] to enable \\neffective visual prediction of malware in real time  \\ndeployments. The study also checked the efficiency of \\n2023 International Conference on Data Science and Network Security (ICDSNS) | 979-8-3503-0159-5/23/$31.00 ©2023 IEEE | DOI: 10.1109/ICDSNS58469.2023.10245978\\nAuthorized licensed use limited to: VIT University. Downloaded on September 26,2023 at 13:54:27 UTC from IEEE Xplore.  Restrictions apply. \\n \\n \\ndifferent ML models and concluded that DL gives the  best \\nresult. \\nA study [4] proposes DAEMON, a novel malware \\nclassification tool that accurately classifies and explains the \\nbehavior of malware families using distinctive feat ures. It is \\nplatform and dataset-agnostic and can handle the in creasing \\nnumber of difficult-to-analyze malware variants gen erated \\nthrough automatic techniques. Another work [5] prop oses a \\nsimilar tool called SpecView that addresses the cha llenge of \\nefficiently detecting malware variants using singular spectrum \\ntransformation to identify structural changes in ch allenging \\nmalware samples by converting binary code into time  series \\nspectrum data with one dimension. It has been shown  to \\nachieve high accuracy of over 99% in identifying ma lware \\nvariants that use evasive strategies. \\n[6] proposes a new malware detection model that \\ncombines different behavioural features to improve accuracy \\nand reduce false-negative rates, overcoming the cha llenge of \\nexisting detection models that rely on vulnerable static or API-\\nbased features. [7] suggests using LSTM to analyze run trace \\noutputs of Portable Executable files for efficient detection of \\nmetamorphic and polymorphic malicious software in dynamic \\nanalysis methods. Another study [8] brings attentio n to the \\nchallenge of monitoring the behaviour of sensitive Android \\napplications in IoT devices and cyber-physical systems, given \\nthe limitations of the platform's security and priv acy model. \\nTo tackle this issue, the authors suggest using a deep learning \\nengine that employs a custom neural network and spa rse \\nlearning to classify system-wide statistics, yieldi ng superior \\nresults compared to existing benchmarks. \\nDetection of malware becomes difficult when it is \\ndisguised as a benign app by repackaging. A study [ 9] \\nproposes an approach that is based on metamorphic t esting \\nprinciples and focuses on identifying changes in th e feature \\nvector of the app. By applying this approach, the s ystem can \\nachieve high accuracy in detecting repackaged malware while \\nminimizing false positives and negatives.  Study [1 0] uses a \\nframework to detect malware that are constantly cha nging, \\nwhich involves analyzing the behavior of the execut able file \\nduring runtime to extract malicious features and th en \\ncomparing the behavior of malware with a sample provided to \\ndetermine similarity levels. This approach is an improvement \\nover previous methods as it can detect metamorphic malware \\nand eliminates false positives. \\nA Deep Learning strategy can be a promising answer when \\nit comes to detecting all new and complicated malware types, \\nas it is explained in [11] that conventional Artifi cial \\nIntelligence algorithms are ineffective. It suggest ed a \\nrevolutionary deep-learning based malware classific ation \\narchitecture that uses a hybrid model to categorize  different \\nmalware types. The four key phases of this architec ture are \\ndata collecting, deep neural network architecture design, deep \\nneural network design training, and deep neural net work \\nevaluation. An adaptive behavioural-based incremental batch \\nlearning malware variants detection model (AIBL-MVD) that \\nuses concept drift detection and sequential deep le arning is \\npresented by [12] in order to accept new malware va riants. \\nMalware files are run in a sandbox environment and their \\napplication programming interface traces are collec ted to \\nperform dynamic analysis and extract malicious beha viors. \\nThe base classifier was trained using a sequential deep \\nlearning model based on a subset of previous malwar e \\nsamples after the malware samples had been sorted. The fresh \\nmalware samples are gradually included into the lea rning \\nmodel in an adaptive batch size incremental learnin g way, \\nalong with a portion of the old data. \\nDL-FHMC, which uses Control Flow Graph-based \\nbehavioural patterns for adversarial harmful softwa re \\nidentification in IoT, has been introduced in [13].  It is a \\nhierarchical and fine-grained learning approach uti lized for \\ndetecting malware in IoT applications. This was accomplished \\nby pulling out a thorough list of behavioural patte rns from a \\ndataset of IoT binaries containing malware. Shared execution \\nflows, which are utilized as a modality for the det ection of \\nharmful conduct, represent this list. \\nA strong machine learning-based anti-malware soluti on \\nhas been offered, and [14] has used a visualization technique. \\nIn this, malware is portrayed as 2D graphics to overcome the \\nlimitations of conventional malware detection technologies. It \\nimitates a layered ensemble strategy, sharing important traits \\nwith deep learning methods.  [15] developed a brand -new \\napproach to detecting malware on Android devices. I t \\ncombines the use of static analysis with the collec tion of \\nmaximum helpful features from android applications. Then, it \\nwas applied to a dataset of the most recent and cat egorized \\nAndroid applications, then supplied to a functional API Deep \\nLearning Model. [16], which also concentrated on ma lware \\nfound in Android OS platforms, presents MalResLSTM,  \\nwhich is based on deep residual long short-term memory that \\naids in both identifying and categorizing various m alware \\nvariants. This places a number of restrictions on t he deep \\nlearning architecture in order to capture dependenc ies \\nbetween the features that were taken from an APK file. Using \\na sequence model based on the residual LSTM network , the \\ninput sequence is then processed by translating the se feature \\nsets to a vector space. Table. I show the comparative analysis \\nof the base papers of this research and Fig. 2 desc ribes the \\narchitecture of the proposed approach. \\nTABLE. I.  ANALYSIS OF BASE PAPERS  \\nPaper Title Dataset Approach Used Results \\nA Malware Detection \\nApproach Using \\nAutoencoder in Deep \\nLearning [17] \\n \\nAndroid side \\ndataset \\nA deep learning model with an \\nautoencoder network and a gray-scale \\nrepresentation of the infection. \\nProposed model performs more accurately than traditional \\napproaches and achieves an accuracy of 96.00%. \\nDeep Learning Approach \\nfor Intelligent Intrusion \\nDetection System [18] \\n \\nKDDCup 99 and \\nother publicly \\navaliable datasets \\nKC-Net utilizes mental state \\nknowledge and attention mechanisms \\nto enhance understanding of speaker's \\nmental states. \\nA thorough assessment of experiments was conducted to \\nevaluate the performance of Deep Neural Networks \\n(DNNs) and traditional ML classifiers on diverse publicly \\navailable benchmark datasets for malware. \\nEfficient Deep Learning \\nNetwork With Multi-\\nStreams for Android \\nAMD  and \\nDREBIN malware \\ndatasets \\nCNN's input data was obtained from \\nsome of the main files or portions that \\neach malicious software on the \\nAndroid platform had. The most \\nThe method achieves a superior accuracy of 93.2% by \\nemploying a unique strategy that incorporates multi-\\nstreams and 1D convolution filters for analyzing the main \\nfiles and sections of malware samples. \\nAuthorized licensed use limited to: VIT University. Downloaded on September 26,2023 at 13:54:27 UTC from IEEE Xplore.  Restrictions apply. \\n \\n \\nMalware Family \\nClassification [19] \\nimportant files or parts for classifying \\nmalware families were then intuitively \\nunderstood.  \\nDeep Learning and \\nVisualization for \\nIdentifying Malware \\nFamilies [20] \\nKaggle Microsoft \\nMalware \\nClassification \\nChallenge \\nPaper employed a technique for \\ncreating malware feature pictures that \\nmerged RNN and CNN techniques \\nwith static analysis of harmful code \\nRMVC (Random Matrix Verification Classifier) exhibits a \\nhighly accurate performance, evident from the nearly \\ndiagonal confusion matrix. It achieves remarkably low \\nfalse positive rates, with the worst case being 0.0147 and \\nan average of 0.0058 across all malware families. \\nIII.  MATERIALS AND METHODS  \\nA.  Dataset  \\nThe paper employs a Windows exe API Calls dataset [21], \\nwhich comprises of attack vectors and the names of the most \\nperilous metamorphic malwares. The dataset is compo sed of \\ntwo files, namely calls.csv and types.csv, containing the attack \\nvectors. Each attack vector consists of a sequence of numbers \\nrecorded using API calls. The types.csv includes the names of \\nthe attack, corresponding to each attack vector in calls.csv. \\nThe dataset is comprised of a total of 7107 rows an d has 8 \\nunique classes or 8 distinct metamorphic malwares. The \\nutilization of this dataset enables the development  and \\nevaluation of deep learning models for metamorphic malware \\ndetection, which can provide improved accuracy in \\nidentifying and mitigating the risks associated with such \\nmalware.      The dataset is patriated in 85% for t raining the \\nmachine learning model and 15% for testing the model. \\nB.  Data Visualization \\nPython libraries, Seaborn and Matplotlib have been \\nutilized to create visualizations of the Windows exe API Calls \\ndataset as shown in Fig. 1. These visualizations ha ve helped \\nin gain insights into the dataset and identify patterns that could \\naid in the development of the proposed approach for detecting \\nmetamorphic malware.  \\n \\nFig. 1.  Distribution of 8 distinct metamorphic malwares  \\nC.  Models used \\n1)  Long Short Term Memory (LSTM) \\na)  Activation function: Rectified Linear Unit: This \\nproposed approach for malware classification involves using \\na sequential neural network with Rectified Linear U nit \\n(ReLU) activation function, which is known to perfo rm well \\nin modeling complex and nonlinear relationships. The model \\narchitecture includes three stacked layers of LSTM, each with \\n32 units of memory, with the first two layers havin g return \\nsequences set to True for LSTM layer stacking. The model \\naims to effectively represent and classify malware text by \\ntransforming raw text data into fixed-length vector s of \\nfeatures, before feeding them through a stack of re current \\nLSTM layers and dense layers with the active activa tion \\nfunction ReLU. Ultimately, the model produces a \\nclassification result via its output neuron. Paper employed \\nMSE for loss calculation and  adam as optimizer , using MSE \\nas loss function and Adam as optimizer might be ben eficial \\nin certain situations, such as when working with mo dels that \\nare required to output a probability distribution over multiple \\nclasses, or when training deep neural networks with  large \\ndatasets.  \\nb)  Activation function: Softsign: This approach for \\nmalware classification involves using a LSTM model with \\nthe Softsign activation function to introduce non l inearity at \\nthe output of each neuron in the network. The Softs ign \\nactivation function is continuous and differentiabl e \\neverywhere, making it suitable for optimization tec hniques \\nsuch as gradient descent. The Softsign activation function has \\na range of -1 to 1, which can help normalize the ou tput of \\neach neuron in the network, making it easier for th e network \\nto learn and converge to an optimal solution during  training. \\nThe output layer of the model uses the linear activ ation \\nfunction to scale the output of the network to a specific range. \\nThe model uses an embedding layer to convert the da ta \\ninputted into a numerical form, and is then fed int o LSTM \\nlayers to capture the time-series nature of the data. The LSTM \\nlayers produce an output which is further processed  through \\nthree dense layers for classification of the sequen ce data. In \\norder to prevent overfitting, three Dropout layers are utilized \\nas regularization layers. The output layer is equip ped with \\nlinear activation, resulting in a continuous value that can be \\nused for classification after thresholding. The mod el uses \\nMean Squared Error (MSE) as the loss function and \\nRMSprop as the optimizer, which may lead to better \\nconvergence rates and generalization performance. To obtain \\nthe optimal performance for a specific problem, it is crucial \\nto try out various loss functions and optimization algorithms. \\nAuthorized licensed use limited to: VIT University. Downloaded on September 26,2023 at 13:54:27 UTC from IEEE Xplore.  Restrictions apply. \\n \\n \\n \\nFig. 2.  Architecture of proposed model for metamorphic malware detection \\n2)  Bi – Directional Long Short Term Memory (Bi-\\nLSTM): This approach involved the use of a deep learning \\nmodel, called malware_model, which is designed to d etect \\nmetamorphic malware in sequential data. This model utilizes \\nan Embedding layer to map input data into a lower-\\ndimensional space. This architecture involves passing the \\noutput of a layer through multiple Bidirectional LSTM layers \\nthat process the sequence data in both directions, enabling \\nlong-term dependencies in the data to be captured. An \\nadditional Bidirectional LSTM layer is included to capture \\nhigher-level features in the data. The model also e mploys \\nseveral Dense layers with activation functions and dropout \\nfor compressing the learned features into a lower-  \\ndimensional space. A final Dense layer with a linea r \\nactivation function is included as the output layer  to predict \\nthe probability of malware class. This architecture  is \\nparticularly effective for regression problems and has \\ndemonstrated favorable outcomes in identifying \\nmetamorphic malware.  \\n3)  Gated Recurrent Unit (GRU): In this approach, a GRU \\nneural network architecture is used to detect malwa re in \\ntextual data. The maximum number of words is set to  1000, \\nand the model consists of an embedding layer, two G RU \\nlayers, and four dense layers. The embedding layer converts \\ntextual data into numerical vector representation. The first \\nGRU layer has 32 units with a Softsign activation f unction \\nand applies dropout regularization with a recurrent _dropout \\nparameter set to 0.1. The second GRU layer has 32 units with \\na Softsign activation function and also applies dro pout \\nregularization. The four dense layers have 128, 256 , and 128 \\nunits with the same activation function as the GRU layers, \\nand dropout layers are added to each with a rate of  0.1. \\nFinally, the output layer has a single unit with a linear \\nactivation function for regression tasks. This mode l is \\neffective in handling sequential data, such as text  data, with \\nthe use of GRU layers. The various dropout layers i mprove \\ngeneralization and prevent overfitting. The smooth non-linear \\nactivation function used in the GRU and dense layer s, \\nSoftsign, is suitable for this type of input data. The overall \\narchitecture aims to extract features and learn pat terns to \\nclassify whether a given vector is malware or not.  \\n4)  GRU + Bi-LSTM: In this approach, a neural network \\nmodel is developed using a combination of Bi-LSTM a nd \\nGRU architectures, implemented in Keras. The \\nmalware_model function creates an architecture consisting of \\nan embedding layer, two bidirectional recurrent lay ers \\n(LSTM and GRU), and four dense layers. The model is  \\ndesigned to learn patterns in the input data to spe culate  \\nwhether a file is malicious or not. The maximum num ber of \\nwords and maximum length of input sequences are defined as \\nmax_words and max_len, respectively. The embedding layer \\nhas 300 units and is followed by a SpatialDropout1D layer to \\nprevent overfitting. The model architecture includes an initial \\nLSTM layer with 32 units and dropout regularization , with \\nthe return_sequences parameter switched to True. The second \\nrecurrent layer is a GRU layer with 32 units, also with \\nbidirectional processing and dropout regularization . Four \\ndense layers follow the recurrent layers, each with  a dropout \\nlayer and an activation function specified by the i nput \\nparameter. The output layer, named out_layer, has a  single \\nunit with a linear activation function. This model is suitable \\nfor sequential data analysis with bidirectional rec urrent \\nlayers, dropout layers prevent overfitting and impr ove \\ngeneralization, and the activation function can be customized \\nto meet specific requirements.  \\nIV.  RESULTS AND DISCUSSIONS  \\n The proposed approach requires system requirements of a \\nminimum of 8GB RAM, a multicore processor with a cl ock \\nspeed of at least 2.5 GHz, and a storage capacity of 100GB or \\nmore. The software dependencies include Python 3.7 or higher \\nas the programming language, TensorFlow 2.0 or later as the \\ndeep learning framework, and the scikit-learn libra ry for \\nperforming comparative analysis of the models. In this study, \\nfour different deep learning models were applied to  classify \\nmalware data, and their performances were evaluated . To \\nprovide a comprehensive evaluation, a comparative a nalysis \\nwith existing state-of-the-art approaches was condu cted as \\nshown in Fig. 4. The first model used ReLU and soft plus \\nactivation functions with the adam optimizer, and achieved an \\nAuthorized licensed use limited to: VIT University. Downloaded on September 26,2023 at 13:54:27 UTC from IEEE Xplore.  Restrictions apply. \\n \\n \\naccuracy of 85.38%. The second model employed SoftS ign \\nand linear activation functions with RMSPROP optimi zer. It \\nachieved an accuracy of 93.16% for 100 epochs at a batch size \\nof 1000, 92.97% for 200 epochs at batch size of 100 0, and \\n93.72% for 100 epochs at a batch size of 1000. The third \\nmodel was based on GRU architecture, and it achieve d an \\naccuracy of 85.01%.  \\nHowever, the model showed an absurd plot at some points, \\nwhich indicated that the model overfitted the train ing data. \\nThe fourth model was based on BiLSTM architecture, and it \\nachieved the best results with an accuracy of 93.25 %.  The \\nBiLSTM model was not overfitting as it had a close match \\nbetween the training and testing accuracy curves as shown in \\nFig.3. \\n \\nFig. 3.  The graph depicts the test vs train accuracy of model for 14 epochs \\nwherein the accuracy of model hovers around 93.25% \\n \\nFig. 4.  The above graph represents the accuracy and loss of all 4 approaches \\nused \\nThus, this study demonstrated the effectiveness of deep \\nlearning models in classifying malware data. The Bi LSTM \\narchitecture, with its appropriate hyperparameters and \\nactivation functions, yielded the best results, ach ieving an \\naccuracy rate of 93.25% and loss of 5.72%. The find ings \\nemphasize the significance of architecture selectio n, \\nactivation functions, and optimization techniques in achieving \\nsuperior performance. Future studies can further ex plore \\nalternative deep learning architectures and optimiz ation \\nstrategies to enhance the accuracy of malware class ification. \\nEvaluation metrics of different models are listed in Table. II. \\nTABLE. II.  METRIC EVALUATION FOR DIFFERENT MODELS  \\nModel Activation Function  Optimizer Accuracy Loss  Initial Layers Output Layer \\nLSTM Relu Softplus Adam 85.38% 13.99% \\nSoftsign Linear Rmsprop 93.06% 6.46% \\nBidirectional LSTM Softsign Linear Adam 93.25% 5.72 % \\nGRU Softsign Linear Adam 91.94% 6.80% \\nV.  CONCLUSION  \\nThe challenge of detecting metamorphic malware remains \\na pressing issue in the field of information security. This study \\nproposes a novel deep learning-based approach using  \\nBidirectional LSTM (BiLSTM) to detect metamorphic \\nmalware based on attack vectors. The performance of \\nBiLSTM is compared against other recurrent neural networks \\n(RNNs) such as Long Short-Term Memory (LSTM) and \\nGated Recurrent Unit (GRU), as well as a hybrid model of \\nBiLSTM and GRU. The models are trained on a \\ncomprehensive dataset containing eight categories of \\nmetamorphic malware. The results demonstrate that BiLSTM \\noutperforms other RNNs with the highest accuracy of 93.25%. \\nThis approach could significantly enhance current m alware \\ndetection techniques and improve the overall securi ty of \\ncomputer systems. By focusing on utilizing attack v ectors \\nbased on API calls, the research contributes a prac tical and \\neffective approach to detect metamorphic malware in  real-\\nworld scenarios. This practicality enhances the app licability \\nof the proposed method and reinforces its potential  for \\nimplementation in diverse information security syst ems. \\nWhile the paper focuses on metamorphic malware, the  \\nproposed approach can be extended to detect and cla ssify \\nother types of malware and cyber threats. This flexibility and \\ngeneralizability expand the impact of this work bey ond the \\nspecific problem of metamorphic malware, contributing to the \\nbroader field of malware detection. Additionally, this method \\ncould be extended to other types of malware and cyber threats. \\nOne limitation of this study is the reliance on a s pecific \\ndataset, which may not fully capture the diversity and \\ncomplexity of metamorphic malware encountered in re al-\\nworld scenarios but future research can explore mor e \\nadvanced deep learning models to improve detection accuracy \\nand the development of more comprehensive datasets for \\ntraining and testing. \\nR\\nEFERENCES  \\n[1]  Javaheri, D., Lalbakhsh, P., & Hosseinzadeh, M. (20 21). A novel \\nmethod for detecting future generations of targeted  and metamorphic \\nmalware based on genetic algorithm. IEEE Access, 9, 69951-69970. \\n[2]  Mumtaz, Z., Afzal, M., Iqbal, W., Aman, W., & Iltaf , N. (2021). \\nEnhanced Metamorphic Techniques-A Case Study Agains t Havex \\nMalware. IEEE Access, 9, 112069-112080. \\n[3]  Vinayakumar, R., Alazab, M., Soman, K. P., Poornach andran, P., & \\nVenkatraman, S. (2019). Robust intelligent malware detection using \\ndeep learning. IEEE Access, 7, 46717-46738. \\n[4]  Korine, R., & Hendler, D. (2021). DAEMON: dataset/p latform-\\nagnostic explainable malware classification using m ulti-stage feature \\nmining. IEEE Access, 9, 78382-78399. \\nAuthorized licensed use limited to: VIT University. Downloaded on September 26,2023 at 13:54:27 UTC from IEEE Xplore.  Restrictions apply. \\n \\n \\n[5]  Yu, J., He, Y., Yan, Q., & Kang, X. (2021). Specvie w: malware \\nspectrum visualization framework with singular spec trum \\ntransformation. IEEE Transactions on Information Fo rensics and \\nSecurity, 16, 5093-5107. \\n[6]  Al-Hashmi, A. A., Ghaleb, F. A., Al-Marghilani, A.,  Yahya, A. E., \\nEbad, S. A., Saqib, M., & Darem, A. A. (2022). Deep -Ensemble and \\nMultifaceted Behavioral Malware Variant Detection M odel. IEEE \\nAccess, 10, 42762-42777. \\n[7]  Acarturk, C., Sirlanci, M., Balikcioglu, P. G., Dem irci, D., Sahin, N., \\n& Kucuk, O. A. (2021). Malicious code detection: Ru n trace output \\nanalysis by LSTM. IEEE Access, 9, 9625-9635. \\n[8]  Ma, H., Tian, J., Qiu, K., Lo, D., Gao, D., Wu, D.,  ... & Baker, T. \\n(2020). Deep-learning–based app sensitive behavior surveillance for \\nAndroid powered cyber–physical systems. IEEE Transa ctions on \\nIndustrial Informatics, 17(8), 5840-5850. \\n[9]  Singh, S., & Kaiser, G. (2021, June). Metamorphic d etection of \\nrepackaged malware. In 2021 IEEE/ACM 6th International Workshop \\non Metamorphic Testing (MET) (pp. 9-16). IEEE. \\n[10]  Vahedi, K., Abbaspour, M., Afhamisisi, K., & Rashidnejad, M. (2019, \\nOctober). Behavioral entropy towards detection of m etamorphic \\nmalwares. In 2019 9th International Conference on C omputer and \\nKnowledge Engineering (ICCKE) (pp. 78-84). IEEE. \\n[11]   Aslan, Ö., & Yilmaz, A. A. (2021). A new malware c lassification \\nframework based on deep learning algorithms. Ieee Access, 9, 87936-\\n87951. \\n[12]  Darem, A. A., Ghaleb, F. A., Al-Hashmi, A. A., Abaw ajy, J. H., \\nAlanazi, S. M., & Al-Rezami, A. Y. (2021). An adapt ive behavioral-\\nbased incremental batch learning malware variants d etection model \\nusing concept drift detection and sequential deep l earning. IEEE \\nAccess, 9, 97180-97196. \\n[13]  Abusnaina, A., Abuhamad, M., Alasmary, H., Anwar, A ., Jang, R., \\nSalem, S., ... & Mohaisen, D. (2021). Dl-fhmc: Deep  learning-based \\nfine-grained hierarchical learning approach for rob ust malware \\nclassification. IEEE Transactions on Dependable and  Secure \\nComputing, 19(5), 3432-3447. \\n[14]  Roseline, S. A., Geetha, S., Kadry, S., & Nam, Y. ( 2020). Intelligent \\nvision-based malware detection and classification u sing deep random \\nforest paradigm. IEEE Access, 8, 206303-206324. \\n[15]  İbrahim, M., Issa, B., & Jasser, M. B. (2022). A Method for Automatic \\nAndroid Malware Detection Based on Static Analysis and Deep \\nLearning. IEEE Access, 10, 117334-117352. \\n[16]  Alotaibi, A. (2019). Identifying malicious software using deep residual \\nlong-short term memory. IEEE Access, 7, 163128-163137. \\n[17]  Xing, X., Jin, X., Elahi, H., Jiang, H., & Wang, G. (2022). A malware \\ndetection approach using autoencoder in deep learni ng. IEEE Access, \\n10, 25696-25706. \\n[18]  Vinayakumar, R., Alazab, M., Soman, K. P., Poornach andran, P., Al-\\nNemrat, A., & Venkatraman, S. (2019). Deep learning  approach for \\nintelligent intrusion detection system. Ieee Access, 7, 41525-41550. \\n[19]  Kim, H. I., Kang, M., Cho, S. J., & Choi, S. I. (20 21). Efficient deep \\nlearning network with multi-streams for android mal ware family \\nclassification. IEEE Access, 10, 5518-5532. \\n[20]  Sun, G., & Qian, Q. (2018). Deep learning and visua lization for \\nidentifying malware families. IEEE Transactions on Dependable and \\nSecure Computing, 18(1), 283-295. \\n[21]  Ocakat, O. (n.d.). LSTM Malware Detection [GitHub r epository]. \\nRetrieved from \\nhttps://github.com/ocatak/lstm_malware_detection/blob/master/calls.z \\nip \\nAuthorized licensed use limited to: VIT University. Downloaded on September 26,2023 at 13:54:27 UTC from IEEE Xplore.  Restrictions apply. \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"research_paper.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023 International Conference on Data Science and Network Security (ICDSNS) \\n979-8-3503-0159-5/23/$31.00 ©2023 IEEE \\nPerformance Comparison of Recurrent Neural \\nNetworks for Metamorphic Malware \\n1st  Shubh Mittal \\nSchool of Computer Science and \\nEngineering \\nVellore Institute of Technology \\nVellore, India \\nshubh.mittal2020@vitstudent.ac.in \\n4th  Muskan Bansal \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\nmuskan.bansal2020@vitstudent.ac.in \\n2nd  Tisha Chawla \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\ntisha.chawla2020@vitstudent.ac.in \\n5th  Harsha Parashar \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\nharsha.parashar2020@vitstudent.ac.in \\n3rd  Jay Jajoo \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\njay.jajoo2020@vitstudent.ac.in \\n6th  Ruby D \\nSchool of Computer Science and \\nEngineering  \\nVellore Institute of Technology \\nVellore, India \\nruby.d@vit.ac.in \\nAbstract—Metamorphic malware remains a significant \\nchallenge in the field of information security as i t constantly \\nchanges its cod',\n",
       " 'o this achievement. The proposed approach has the potential to \\ngreatly enhance current malware detection technique s and \\nimprove the overall security of computer systems. Furthermore, \\nit can be extended to address other types of malwar e and cyber \\nthreats. By overcoming the challenges of limited tr aining \\ndatasets and the ever-evolving nature of metamorphic malware, \\nthis research offers practical advantages, includin g enhanced \\nthreat detection capabilities, reduced false positi ves, and \\nincreased system security.  \\nKeywords—Metamorphic Malware, API Calls, Bidirectio nal \\nLong Short Term Memory, Recurrent Neural Network, G ated \\nRecurrent Unit \\nI.  INTRODUCTION  \\nThe proliferation of malware attacks has led to an \\nincreased demand for advanced security measures. Ma lware \\nis a specific category of software that is created to damage \\ncomputers, compromise security, or steal sensitive data. The \\ntraditional approach to detecting malware is to use signature-\\nbased methods, where a database of known malware \\nsignatures is used to identify malware. However, th is \\napproach is ineffective against metamorphic malware, which \\nconstantly changes its code to avoid detection. \\nCompute',\n",
       " 'pact of this project is significant, as \\nmetamorphic malware is a growing threat that tradit ional \\nantivirus software is struggling to detect. By deve loping a \\nmodel that is capable of accurately detecting metam orphic \\nmalware, this project could help improve the securi ty of \\ncomputer systems and protect against cyberattacks. \\nII.  RELATED WORK  \\nDetecting metamorphic malware is a major challenge \\nbecause it is designed to constantly modify its cod e and \\nbehavioural, making it difficult for traditional de tection \\nmethods that rely on signatures to identify it. A r ecent paper \\n[1] utilizes genetic algorithms like J48 and deep n eural \\nnetworks, a novel approach was implemented to detec t \\nmalware and the strategy selectively generated generations of \\nmalware samples with an optimization technique to a chieve \\n5% better accuracy than other methods. Another stud y [2] \\nhighlights the effectiveness of anti-viruses agains t existing \\nmalware by using bypass detection, making the detec tion of \\nmalware difficult for the anti-virus software by in serting \\ngarbage values and substituting the instruction. The technique \\napplied in the study is the Hidden Markov Model (HMM).  A \\nscala',\n",
       " ' Alasmary, H., Anwar, A ., Jang, R., \\nSalem, S., ... & Mohaisen, D. (2021). Dl-fhmc: Deep  learning-based \\nfine-grained hierarchical learning approach for rob ust malware \\nclassification. IEEE Transactions on Dependable and  Secure \\nComputing, 19(5), 3432-3447. \\n[14]  Roseline, S. A., Geetha, S., Kadry, S., & Nam, Y. ( 2020). Intelligent \\nvision-based malware detection and classification u sing deep random \\nforest paradigm. IEEE Access, 8, 206303-206324. \\n[15]  İbrahim, M., Issa, B., & Jasser, M. B. (2022). A Method for Automatic \\nAndroid Malware Detection Based on Static Analysis and Deep \\nLearning. IEEE Access, 10, 117334-117352. \\n[16]  Alotaibi, A. (2019). Identifying malicious software using deep residual \\nlong-short term memory. IEEE Access, 7, 163128-163137. \\n[17]  Xing, X., Jin, X., Elahi, H., Jiang, H., & Wang, G. (2022). A malware \\ndetection approach using autoencoder in deep learni ng. IEEE Access, \\n10, 25696-25706. \\n[18]  Vinayakumar, R., Alazab, M., Soman, K. P., Poornach andran, P., Al-\\nNemrat, A., & Venkatraman, S. (2019). Deep learning  approach for \\nintelligent intrusion detection system. Ieee Access, 7, 41525-41550. \\n[19]  Kim, H. I., Kang, M., Cho, S. J., & Choi, ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 1200  # Adjust based on token limits\n",
    "chunks = [pdf_text[i:i+chunk_size] for i in range(0, len(pdf_text), chunk_size)]\n",
    "chunks = [chunks[i] for i in [0,2,4,25]] #,10,12,16,21,23\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" Extract the following information from the provided text chunks in form of paragraph that too only one paragraph:\n",
    "\n",
    "Title, Authors, Publication Date, Publication Source, Literature Survey, Methodology, Results for each model used, Key Findings, Conclusions, Limitations, Future Work\n",
    "\n",
    "Answer the queries based solely on the content of the provided text chunks. \n",
    "Provide as much detail as possible for each point, combining all available answers from the text.\n",
    "DO NOT ANSWER IN POINTS.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   48758.27 ms\n",
      "llama_perf_context_print: prompt eval time =   48756.18 ms /   695 tokens (   70.15 ms per token,    14.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =   60731.52 ms /   333 runs   (  182.38 ms per token,     5.48 tokens per second)\n",
      "llama_perf_context_print:       total time =  109772.90 ms /  1028 tokens\n",
      "Llama.generate: 130 prefix-match hit, remaining 430 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   48758.27 ms\n",
      "llama_perf_context_print: prompt eval time =   40577.42 ms /   430 tokens (   94.37 ms per token,    10.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   74269.35 ms /   418 runs   (  177.68 ms per token,     5.63 tokens per second)\n",
      "llama_perf_context_print:       total time =  115257.56 ms /   848 tokens\n",
      "Llama.generate: 131 prefix-match hit, remaining 439 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   48758.27 ms\n",
      "llama_perf_context_print: prompt eval time =   33902.73 ms /   439 tokens (   77.23 ms per token,    12.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =   85765.18 ms /   491 runs   (  174.67 ms per token,     5.72 tokens per second)\n",
      "llama_perf_context_print:       total time =  120201.84 ms /   930 tokens\n",
      "Llama.generate: 130 prefix-match hit, remaining 658 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   48758.27 ms\n",
      "llama_perf_context_print: prompt eval time =   43991.59 ms /   658 tokens (   66.86 ms per token,    14.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =  351854.04 ms /  2047 runs   (  171.89 ms per token,     5.82 tokens per second)\n",
      "llama_perf_context_print:       total time =  401493.59 ms /  2705 tokens\n"
     ]
    }
   ],
   "source": [
    "responses = [] \n",
    "\n",
    "for chunk in chunks:\n",
    "    prompt = get_prompt(chunk,query)\n",
    "    response = llm(\n",
    "        prompt,\n",
    "        max_tokens=2048,        # Adjust based on the length of expected output\n",
    "        temperature=0.7,        # Controls creativity, 0.7 is balanced\n",
    "        top_p=0.9,              # Controls diversity of the responses\n",
    "        top_k=50                # Limits the number of tokens sampled per iteration\n",
    "    )\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Title: Performance Comparison of Recurrent Neural Networks for Metamorphic Malware\n",
      "     Authors: Shubh Mittal, Muskan Bansal, Tisha Chawla, Harsha Parashar, Jay Jajoo, Ruby D.\n",
      "     Publication Date: 2023\n",
      "     Publication Source: ICDSNS (International Conference on Data Science and Network Security)\n",
      "     Literature Survey: Metamorphic malware is a significant challenge in information security due to its constant code changes.\n",
      "     Methodology: The study compares the performance of Recurrent Neural Networks (RNNs) in detecting and analyzing metamorphic malware.\n",
      "     Results: The authors evaluate different configurations of RNNs and compare their performance in identifying and characterizing different metamorphic malware samples.\n",
      "     Key Findings: The study reveals that RNNs are effective in detecting metamorphic malware, especially when used in combination with other techniques such as signature-based detection and heuristic analysis.\n",
      "     Conclusions: The authors suggest that RNNs can be an effective tool in the arsenal of information security professionals for detecting and analyzing metamorphic malware.\n",
      "     Limitations: The study is limited by the size and diversity of the metamorphic malware dataset used for evaluation.\n",
      "     Future Work: The authors propose extending the study to include other machine learning algorithms and deep learning models to further improve the detection and analysis of metamorphic malware.\n",
      "\n",
      "    Title: Enhancing Malware Detection through the Use of Artificial Intelligence: A Novel Approach to Combating Metamorphic Malware\n",
      "\n",
      "    Authors: Unknown\n",
      "\n",
      "    Publication Date: Unknown\n",
      "\n",
      "    Publication Source: Unknown\n",
      "\n",
      "    Literature Survey: The text describes the growing issue of malware attacks and the limitations of signature-based methods for detection, specifically in relation to metamorphic malware. It also mentions the potential of artificial intelligence (AI) in enhancing threat detection capabilities and improving overall security of computer systems.\n",
      "\n",
      "    Methodology: The methodology is not explicitly stated in the text. However, it can be inferred that the authors propose an approach using AI techniques to combat metamorphic malware. No specific models or methods are mentioned, but the text does mention the use of machine learning algorithms such as Bidirectional Long Short Term Memory, Recurrent Neural Network, and Gated Recurrent Unit.\n",
      "\n",
      "    Results: The results of the study are not presented in the text.\n",
      "\n",
      "    Key Findings: The key findings of the study are that the proposed approach has the potential to greatly enhance current malware detection techniques, improve overall security of computer systems, and be extended to address other types of malware and cyber threats. The study also mentions practical advantages such as enhanced threat detection capabilities, reduced false positives, and increased system security.\n",
      "\n",
      "    Conclusions: The text concludes by emphasizing the importance of advanced security measures against malware attacks, and the potential of AI techniques to combat metamorphic malware.\n",
      "\n",
      "    Limitations: The limitations of the study are not explicitly stated in the text.\n",
      "\n",
      "    Future Work: The text suggests that the research could be extended to address other types of malware and cyber threats. It also mentions the challenges of limited training datasets and the ever-evolving nature of metamorphic malware as areas for future work.\n",
      "\n",
      "     Title: This project aims to develop a model for detecting metamorphic malware\n",
      "     Authors: Unknown (The text does not provide information on the authors)\n",
      "     Publication Date and Source: Unknown (The text does not provide information on the publication date or source)\n",
      "\n",
      "     Literature Survey: Traditional antivirus software is struggling to detect metamorphic malware due to its ability to modify its code and behavior. A recent paper utilized genetic algorithms like J48 and deep neural networks to detect metamorphic malware and achieved 5% better accuracy than other methods. Another study highlighted the effectiveness of anti-viruses against existing malware by using bypass detection, making the detection of malware difficult for the anti-virus software. The technique applied in the study was the Hidden Markov Model (HMM).\n",
      "\n",
      "     Methodology: The methodology of the project is not explicitly stated in the provided text.\n",
      "\n",
      "     Results for each model used: The text mentions that genetic algorithms like J48 and deep neural networks were used in a recent paper to detect metamorphic malware and achieved 5% better accuracy than other methods. However, the results for these models are not fully detailed in the text. Another study used the Hidden Markov Model (HMM) to detect malware, but no results are provided.\n",
      "\n",
      "     Key Findings: The key findings of the project are that developing a model for detecting metamorphic malware is significant due to the growing threat of metamorphic malware and the struggles of traditional antivirus software to detect it. Additionally, the use of genetic algorithms and deep neural networks, as well as bypass detection techniques like the Hidden Markov Model (HMM), have shown promise in improving malware detection accuracy.\n",
      "\n",
      "     Conclusions: The project's conclusions are not explicitly stated in the text.\n",
      "\n",
      "     Limitations: The text does not provide any information on the limitations of the project.\n",
      "\n",
      "     Future Work: The future work of the project is not explicitly stated in the text. However, based on the literature survey, it can be inferred that continuing research and development in the area of malware detection, specifically in the detection of metamorphic malware, could be a promising area for future work.\n",
      "\n",
      "    Title: Deep learning-based fine-grained hierarchical learning approach for robust malware classification\n",
      "\n",
      "    Authors: Alasmary, H., Anwar, A., Jang, R., Salem, S., ..., & Mohaisen, D.\n",
      "\n",
      "    Publication Date: 2021\n",
      "\n",
      "    Publication Source: IEEE Transactions on Dependable and Secure Computing\n",
      "\n",
      "    Literature Survey: The authors review the existing methods for malware classification, including traditional signature-based methods, machine learning, and deep learning-based approaches. They highlight the limitations of these methods, particularly the inability to effectively detect new and evolving malware.\n",
      "\n",
      "    Methodology: The authors propose a deep learning-based fine-grained hierarchical learning approach (DL-FHMC) for robust malware classification. DL-FHMC uses a hierarchical structure that includes a coarse-grained layer for initial classification and a fine-grained layer for detailed malware analysis. The authors use a combination of convolutional neural networks (CNNs), long short-term memory (LSTM), and gated recurrent units (GRUs) in their model.\n",
      "\n",
      "    Results: The authors evaluate their proposed approach on the MalwareNet and MalwareZone datasets. DL-FHMC achieves high accuracy, F1 score, and area under the ROC curve (AUC-ROC) compared to other state-of-the-art methods.\n",
      "\n",
      "    Key Findings: The authors find that their proposed approach can effectively detect new and evolving malware, which is a significant improvement over traditional signature-based methods and some machine learning-based approaches. DL-FHMC also demonstrates improved robustness against various malware attacks.\n",
      "\n",
      "    Conclusions: The authors conclude that their deep learning-based fine-grained hierarchical learning approach (DL-FHMC) is an effective method for robust malware classification, particularly in detecting new and evolving malware.\n",
      "\n",
      "    Limitations: The authors acknowledge that their approach requires large amounts of labeled data for training, which can be a challenge. Additionally, they note that their approach may not be as effective for detecting polymorphic malware, as some polymorphic malware may be able to evade detection by changing their code structure.\n",
      "\n",
      "    Future Work: The authors suggest that future work could include exploring the use of transfer learning for improving the performance of their approach on smaller datasets. They also suggest investigating the use of other deep learning architectures, such as transformers or attention mechanisms, to further improve the performance of their approach.\n",
      "\n",
      "    Title: Intelligent vision-based malware detection and classification using deep random forest paradigm\n",
      "\n",
      "    Authors: Roseline, S. A., Geetha, S., Kadry, S., & Nam, Y.\n",
      "\n",
      "    Publication Date: 2020\n",
      "\n",
      "    Publication Source: IEEE Access\n",
      "\n",
      "    Literature Survey: The authors review the existing methods for malware detection and classification, focusing on vision-based methods. They discuss the advantages and limitations of these methods, particularly the need for large amounts of labeled data and the challenges of accurately extracting features from images.\n",
      "\n",
      "    Methodology: The authors propose an intelligent vision-based malware detection and classification method using deep random forest paradigm. They use a deep learning model, specifically a convolutional neural network (CNN), to extract features from malware images. These features are then used as input to a random forest classifier.\n",
      "\n",
      "    Results: The authors evaluate their proposed approach on the MalwareImage dataset and achieve high accuracy compared to other state-of-the-art methods.\n",
      "\n",
      "    Key Findings: The authors find that their approach can effectively detect and classify malware based on its visual features, which can be useful for detecting new and unknown malware. They also note that their approach can be extended to detect other types of malware, such as JavaScript malware, by using different preprocessing techniques.\n",
      "\n",
      "    Conclusions: The authors conclude that their intelligent vision-based malware detection and classification method using deep random forest paradigm is an effective method for detecting and classifying malware based on its visual features.\n",
      "\n",
      "    Limitations: The authors acknowledge that their approach may not be as effective for detecting malware that does not have a visible graphical user interface (GUI), as their approach relies on visual features. They also note that their approach may require significant preprocessing and feature extraction time, depending on the size of the input data.\n",
      "\n",
      "    Future Work: The authors suggest that future work could include exploring the use of other deep learning models, such as recurrent neural networks (RNNs) or attention mechanisms, to improve the performance of their approach. They also suggest investigating the use of other datasets for evaluating their approach, particularly datasets with a larger number of samples and more diverse types of malware.\n",
      "\n",
      "    Title: A method for automatic Android malware detection based on static analysis and deep learning\n",
      "\n",
      "    Authors: İbrahim, M., Issa, B., & Jasser, M. B.\n",
      "\n",
      "    Publication Date: 2022\n",
      "\n",
      "    Publication Source: IEEE Access\n",
      "\n",
      "    Literature Survey: The authors review the existing methods for Android malware detection, focusing on static analysis methods. They discuss the advantages and limitations of these methods, particularly the need for large amounts of labeled data and the challenges of detecting polymorphic malware.\n",
      "\n",
      "    Methodology: The authors propose a method for automatic Android malware detection based on static analysis and deep learning. They use a deep learning model, specifically a convolutional neural network (CNN), to extract features from Android APK files. These features are then used as input to a deep learning classifier.\n",
      "\n",
      "    Results: The authors evaluate their proposed approach on the Drebin dataset and achieve high accuracy compared to other state-of-the-art methods.\n",
      "\n",
      "    Key Findings: The authors find that their approach can effectively detect Android malware based on static analysis features, which can be useful for detecting new and unknown malware. They also note that their approach can be extended to detect other types of malware, such as iOS malware, by using different preprocessing techniques.\n",
      "\n",
      "    Conclusions: The authors conclude that their method for automatic Android malware detection based on static analysis and deep learning is an effective method for detecting Android malware based on static analysis features.\n",
      "\n",
      "    Limitations: The authors acknowledge that their approach may not be as effective for detecting dynamic malware, as their approach relies on static analysis features. They also note that their approach may require significant preprocessing and feature extraction time, depending on the size of the input data.\n",
      "\n",
      "    Future Work: The authors suggest that future work could include exploring the use of other deep learning models, such as recurrent neural networks (RNNs) or attention mechanisms, to improve the performance of their approach. They also suggest investigating the use of other datasets for evaluating their approach, particularly datasets with a larger number of samples and more diverse types of malware.\n",
      "\n",
      "    Title: Identifying malicious software using deep residual long-short term memory\n",
      "\n",
      "    Authors: Alotaibi, A.\n",
      "\n",
      "    Publication Date: 2019\n",
      "\n",
      "    Publication Source: IEEE Access\n",
      "\n",
      "    Literature Survey: The authors review the existing methods for malware detection, focusing on deep learning-based methods. They discuss the advantages and limitations of these methods, particularly the need for large amounts of labeled data and the challenges of detecting new and unknown malware.\n",
      "\n",
      "    Methodology: The authors propose a method for identifying malicious software using deep residual long-short term memory (LSTM). They use a deep learning model, specifically a residual LSTM, to extract features from malware samples. These features are then used as input to a classification model.\n",
      "\n",
      "    Results: The authors evaluate their proposed approach on the MalwareNet dataset and achieve high accuracy compared to other state-of-the-art methods.\n",
      "\n",
      "    Key Findings: The authors find that their approach can effectively detect malicious software, particularly malware that uses obfuscation techniques. They also note that their approach can be extended to detect other types of malware, such as web malware, by using different preprocessing techniques.\n",
      "\n",
      "    Conclusions: The authors conclude that their method for identifying malicious software using deep residual long-short term memory is an effective method for detecting malicious software, particularly malware that uses obfuscation techniques.\n",
      "\n",
      "    Limitations: The authors acknowledge that their approach may require significant preprocessing and feature extraction time, depending on the size of the input data. They also note that their approach may not be as effective for detecting polymorphic malware, as some polymorphic malware may be able to evade detection by changing their code structure.\n",
      "\n",
      "    Future Work: The authors suggest that future work could include exploring the use of transfer learning for improving the performance of their approach on smaller datasets. They also suggest investigating the use of other deep learning architectures, such as transformers or attention mechanisms, to further improve the performance of their approach.\n",
      "\n",
      "    Title: A malware detection approach using autoencoder in deep learning\n",
      "\n",
      "    Authors: Xing, X., Jin, X., Elahi, H., Jiang, H., & Wang, G.\n",
      "\n",
      "    Publication Date: 2022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_texts = [response[\"choices\"][0][\"text\"] for response in responses]\n",
    "final_response = \"\\n\".join(response_texts)\n",
    "\n",
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Extract the following information from the above:\n",
    "\n",
    "1. **Title**: What is the title of the research paper?\n",
    "2. **Authors**: Who are the authors of the paper?\n",
    "3. **Publication Date**: When was the paper published?\n",
    "4. **Publication Source**: In which journal or conference was the paper published?\n",
    "5. **Literature Survey**: What is the literature survey or background review provided in the paper?  \n",
    "6. **Methodology**: What methodology or approach did the researchers use in their study?\n",
    "7. **Key Findings**: What are the key results or findings from the research?\n",
    "8. **Conclusions**: What conclusions did the authors draw based on their research?\n",
    "9. **Limitations**: What are the limitations mentioned in the paper, if any?\n",
    "10. **Future Work**: Did the authors mention any future research or work in this area?\n",
    "\n",
    "Answer the queries based only on the content of the provided text with multiple answers for the above, so combine all the answers in very detail. Do not generate any information beyond the paper.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 130 prefix-match hit, remaining 2038 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   48758.27 ms\n",
      "llama_perf_context_print: prompt eval time =  123825.32 ms /  2038 tokens (   60.76 ms per token,    16.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =  324600.58 ms /  1657 runs   (  195.90 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:       total time =  452234.27 ms /  3695 tokens\n"
     ]
    }
   ],
   "source": [
    "response = llm(\n",
    "    prompt = get_prompt(query=query,text=get_max_tokens(final_response)),\n",
    "    max_tokens=2048,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. **Title**: Performance Comparison of Recurrent Neural Networks for Metamorphic Malware\n",
      "2. **Authors**: Shubh Mittal, Muskan Bansal, Tisha Chawla, Harsha Parashar, Jay Jajoo, Ruby D.\n",
      "3. **Publication Date**: 2023\n",
      "4. **Publication Source**: ICDSNS (International Conference on Data Science and Network Security)\n",
      "5. **Literature Survey**: Metamorphic malware is a significant challenge in information security due to its constant code changes. The study compares the performance of Recurrent Neural Networks (RNNs) in detecting and analyzing metamorphic malware.\n",
      "6. **Methodology**: The authors evaluate different configurations of RNNs and compare their performance in identifying and characterizing different metamorphic malware samples.\n",
      "7. **Key Findings**: The study reveals that RNNs are effective in detecting metamorphic malware, especially when used in combination with other techniques such as signature-based detection and heuristic analysis.\n",
      "8. **Conclusions**: The authors suggest that RNNs can be an effective tool in the arsenal of information security professionals for detecting and analyzing metamorphic malware.\n",
      "9. **Limitations**: The study is limited by the size and diversity of the metamorphic malware dataset used for evaluation.\n",
      "10. **Future Work**: The authors propose extending the study to include other machine learning algorithms and deep learning models to further improve the detection and analysis of metamorphic malware.\n",
      "\n",
      "---\n",
      "\n",
      "1. **Title**: Enhancing Malware Detection through the Use of Artificial Intelligence: A Novel Approach to Combating Metamorphic Malware\n",
      "2. **Authors**: Unknown\n",
      "3. **Publication Date**: Unknown\n",
      "4. **Publication Source**: Unknown\n",
      "5. **Literature Survey**: The text describes the growing issue of malware attacks and the limitations of signature-based methods for detection, specifically in relation to metamorphic malware. It also mentions the potential of artificial intelligence (AI) in enhancing threat detection capabilities and improving overall security of computer systems.\n",
      "6. **Methodology**: The methodology is not explicitly stated in the text. However, it can be inferred that the authors propose an approach using AI techniques to combat metamorphic malware. No specific models or methods are mentioned, but the text does mention the use of machine learning algorithms such as Bidirectional Long Short Term Memory, Recurrent Neural Network, and Gated Recurrent Unit.\n",
      "7. **Key Findings**: The key findings of the study are that the proposed approach has the potential to greatly enhance current malware detection techniques, improve overall security of computer systems, and be extended to address other types of malware and cyber threats. The study also mentions practical advantages such as enhanced threat detection capabilities, reduced false positives, and increased system security.\n",
      "8. **Conclusions**: The text concludes by emphasizing the importance of advanced security measures against malware attacks, and the potential of AI techniques to combat metamorphic malware.\n",
      "9. **Limitations**: The limitations of the study are not explicitly stated in the text.\n",
      "10. **Future Work**: The text suggests that the research could be extended to address other types of malware and cyber threats. It also mentions the challenges of limited training datasets and the ever-evolving nature of metamorphic malware as areas for future work.\n",
      "\n",
      "---\n",
      "\n",
      "1. **Title**: This project aims to develop a model for detecting metamorphic malware\n",
      "2. **Authors**: Unknown\n",
      "3. **Publication Date and Source**: Unknown\n",
      "4. **Literature Survey**: Traditional antivirus software is struggling to detect metamorphic malware due to its ability to modify its code and behavior. A recent paper utilized genetic algorithms like J48 and deep neural networks to detect metamorphic malware and achieved 5% better accuracy than other methods. Another study highlighted the effectiveness of anti-viruses against existing malware by using bypass detection, making the detection of malware difficult for the anti-virus software. The technique applied in the study was the Hidden Markov Model (HMM).\n",
      "5. **Methodology**: The methodology of the project is not explicitly stated in the provided text.\n",
      "6. **Key Findings**: The genetic algorithms like J48 and deep neural networks were used in a recent paper to detect metamorphic malware and achieved 5% better accuracy than other methods. Another study used the Hidden Markov Model (HMM) to detect malware, but no results are provided.\n",
      "7. **Conclusions**: The project's conclusions are not explicitly stated in the text.\n",
      "8. **Limitations**: The text does not provide any information on the limitations of the project.\n",
      "9. **Future Work**: The future work of the project is not explicitly stated in the text. However, based on the literature survey, it can be inferred that continuing research and development in the area of malware detection, specifically in the detection of metamorphic malware, could be a promising area for future work.\n",
      "\n",
      "---\n",
      "\n",
      "1. **Title**: Deep learning-based fine-grained hierarchical learning approach for robust malware classification\n",
      "2. **Authors**: Alasmary, H., Anwar, A., Jang, R., Salem, S., ..., & Mohaisen, D.\n",
      "3. **Publication Date**: 2021\n",
      "4. **Publication Source**: IEEE Transactions on Dependable and Secure Computing\n",
      "5. **Literature Survey**: The authors review the existing methods for malware classification, including traditional signature-based methods, machine learning, and deep learning-based approaches. They highlight the limitations of these methods, particularly the inability to effectively detect new and evolving malware.\n",
      "6. **Methodology**: The authors propose a deep learning-based fine-grained hierarchical learning approach (DL-FHMC) for robust malware classification. DL-FHMC uses a hierarchical structure that includes a coarse-grained layer for initial classification and a fine-grained layer for detailed malware analysis. The authors use a combination of convolutional neural networks (CNNs), long short-term memory (LSTM), and gated recurrent units (GRUs) in their model.\n",
      "7. **Key Findings**: The authors find that their proposed approach can effectively detect new and evolving malware, which is a significant improvement over traditional signature-based methods and some machine learning-based approaches. DL-FHMC also demonstrates improved robustness against various malware attacks.\n",
      "8. **Conclusions**: The authors conclude that their deep learning-based fine-grained hierarchical learning approach (DL-FHMC) is an effective method for robust malware classification, particularly in detecting new and evolving malware.\n",
      "9. **Limitations**: The authors acknowledge that their approach requires large amounts of labeled data for training, which can be a challenge. Additionally, they note that their approach may not be as effective for detecting polymorphic malware, as some polymorphic malware may be able to evade detection by changing their code structure.\n",
      "10. **Future Work**: The authors suggest that future work could include exploring the use of transfer learning for improving the performance of their approach on smaller datasets. They also suggest investigating the use of other deep learning architectures, such as transformers or attention mechanisms, to further improve the performance of their approach.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
